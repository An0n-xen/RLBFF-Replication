{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c90ab599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"nvidia/HelpSteer3\", \"feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae985b20",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "    Feedback: {feedback}\n",
    "\n",
    "    Generate a list of principles that the response is evaluated against in the feedback.\n",
    "    For each principle, identify a text span from the feedback relating to this principle and then state whether the text span suggests that the response satisfies the principle yes/no/partially.\n",
    "\n",
    "    Return it as a json dictionary in the format {{\"<principle 1>\": \"<supporting text span>-<yes/no/partially>\", \"<principle 2>\": \"<supporting text span>-<yes/no/partially>\".}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b5639",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_data = ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791b2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['domain', 'language', 'context', 'response1', 'response2', 'feedback1', 'feedback2'],\n",
       "    num_rows: 38782\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c3fb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2dadab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['domain', 'language', 'context', 'response1', 'response2', 'feedback1',\n",
       "       'feedback2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b149c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain: code\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "language: python\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "context: [{'role': 'user', 'content': \"i'd like to create a docker-compose file that sets up our net core backend with azurite emulator and a react frontend\"}, {'role': 'assistant', 'content': 'To create a `docker-compose.yml` file that sets up your .NET Core backend, Azure Storage Emulator (Azurite), and a React frontend, you can use the following template. Make sure to replace the placeholders with your actual service names, paths, and configurations.\\n\\n```yaml\\nversion: \\'3.8\\'\\nservices:\\n  backend:\\n    image: mcr.microsoft.com/dotnet/core/aspnet:3.1\\n    volumes:\\n      - ./backend:/app\\n    working_dir: /app\\n    command: [\"dotnet\", \"watch\", \"run\"]\\n    ports:\\n      - 5000:5000\\n      - 5001:5001\\n    depends_on:\\n      - azurite\\n\\n  azurite:\\n    image: mcr.microsoft.com/azure-storage/azurite\\n    volumes:\\n      - azurite-data:/data\\n    command: [\"azurite\", \"--blobHost\", \"0.0.0.0\"]\\n    ports:\\n      - 10000:10000\\n\\n  frontend:\\n    image: node:14\\n    volumes:\\n      - ./frontend:/app\\n    working_dir: /app\\n    command: [\"npm\", \"start\"]\\n    ports:\\n      - 3000:3000\\n    depends_on:\\n      - backend\\n\\nvolumes:\\n  azurite-data:\\n```\\n\\nThis `docker-compose.yml` file sets up three services:\\n\\n1. `backend`: A .NET Core backend service using the official Microsoft ASP.NET Core image. It mounts the `backend` directory from your local machine to the container\\'s `/app` directory and runs the `dotnet watch run` command to start the application. It also depends on the `azurite` service.\\n2. `azurite`: An Azure Storage Emulator (Azurite) service using the official Microsoft Azurite image. It mounts a volume named `azurite-data` to the container\\'s `/data` directory for persistent storage. It also exposes port 10000 for the Blob service.\\n3. `frontend`: A React frontend service using the official Node.js image. It mounts the `frontend` directory from your local machine to the container\\'s `/app` directory and runs the `npm start` command to start the application. It also depends on the `backend` service.\\n\\nBefore running `docker-compose up`, make sure you have the following prerequisites:\\n\\n1. Docker installed on your machine.\\n2. Your .NET Core backend project is located in a directory named `backend` in the same directory as the `docker-compose.yml` file.\\n3. Your React frontend project is located in a directory named `frontend` in the same directory as the `docker-compose.yml` file.\\n4. Both the backend and frontend projects have their respective dependencies installed (e.g., `dotnet restore` and `npm install`).\\n\\nOnce you have everything set up, you can run `docker-compose up` to start the services.'}, {'role': 'user', 'content': 'how do i build and run a net core 6.0 solution file for the backend'}]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "response1: To build and run a .NET Core 6.0 solution file for the backend, you can follow these steps:\n",
      "\n",
      "1. Make sure you have the .NET Core 6.0 SDK installed on your machine. You can download it from the official Microsoft website: <https://dotnet.microsoft.com/download/dotnet/6.0>\n",
      "2. Open a terminal or command prompt and navigate to the directory containing your .NET Core 6.0 solution file (`.sln`).\n",
      "3. Run the following command to restore the NuGet packages for the solution:\n",
      "\n",
      "   ```\n",
      "   dotnet restore MySolution.sln\n",
      "   ```\n",
      "\n",
      "   Replace `MySolution.sln` with the actual name of your solution file.\n",
      "\n",
      "4. After the packages are restored, you can build the solution using the following command:\n",
      "\n",
      "   ```\n",
      "   dotnet build MySolution.sln\n",
      "   ```\n",
      "\n",
      "   This command will build all the projects in the solution and generate the binaries in the `bin` directory for each project.\n",
      "\n",
      "5. To run the solution, you need to navigate to the directory of the project you want to run and execute the following command:\n",
      "\n",
      "   ```\n",
      "   dotnet run\n",
      "   ```\n",
      "\n",
      "   Replace the command with `dotnet run --project MyProject` if you want to specify the project to run explicitly.\n",
      "\n",
      "   This command will start the project and run it on the default .NET Core web server, which listens on port 5000 for HTTP and 5001 for HTTPS.\n",
      "\n",
      "If you want to run the solution in a Docker container, you can create a Dockerfile for your project and use the `docker build` and `docker run` commands to build and run the container. Here's an example Dockerfile for a .NET Core 6.0 project:\n",
      "\n",
      "```dockerfile\n",
      "# Use the official Microsoft .NET Core 6.0 SDK image as the base image\n",
      "FROM mcr.microsoft.com/dotnet/sdk:6.0 AS build\n",
      "\n",
      "# Set the working directory to the root directory of the project\n",
      "WORKDIR /app\n",
      "\n",
      "# Copy the project files to the container\n",
      "COPY . .\n",
      "\n",
      "# Restore the NuGet packages for the project\n",
      "RUN dotnet restore\n",
      "\n",
      "# Build the project and generate the binaries\n",
      "RUN dotnet build --configuration Release\n",
      "\n",
      "# Set the entry point for the container to the compiled binary\n",
      "ENTRYPOINT [\"dotnet\", \"MyProject.dll\"]\n",
      "```\n",
      "\n",
      "Replace `MyProject` with the actual name of your project.\n",
      "\n",
      "After creating the Dockerfile, you can build the Docker image using the following command:\n",
      "\n",
      "```\n",
      "docker build -t my-backend-image .\n",
      "```\n",
      "\n",
      "This command will build the Docker image with the tag `my-backend-image`.\n",
      "\n",
      "Once the image is built, you can run the container using the following command:\n",
      "\n",
      "```\n",
      "docker run -p 5000:5000 -p 5001:5001 my-backend-image\n",
      "```\n",
      "\n",
      "This command will start the container and map the container's ports 5000 and 5001 to the host's ports 5000 and 5001, respectively.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "response2:  To add a Redis service to your `docker-compose.yml` file, you can include the following configuration:\n",
      "\n",
      "```yaml\n",
      "  redis:\n",
      "    image: \"redis:alpine\"\n",
      "    ports:\n",
      "      - \"6379:6379\"\n",
      "```\n",
      "\n",
      "This will create a Redis service using the official Redis image based on Alpine Linux. It will expose port 6379, which is the default Redis port.\n",
      "\n",
      "To use the Redis service in your .NET Core backend application, you'll need to install the `StackExchange.Redis` NuGet package. You can do this by running the following command in your backend project directory:\n",
      "\n",
      "```bash\n",
      "dotnet add package StackExchange.Redis\n",
      "```\n",
      "\n",
      "Once you have the package installed, you can configure your application to connect to the Redis service using the connection string provided by the `redis` service in your `docker-compose.yml` file.\n",
      "\n",
      "Here's an example of how you can configure the Redis connection string in your `appsettings.json` file:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"ConnectionStrings\": {\n",
      "    \"Redis\": \"redis://localhost:6379\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "In your backend code, you can then use the `ConnectionMultiplexer` class from the `StackExchange.Redis` package to connect to the Redis service:\n",
      "\n",
      "```csharp\n",
      "using StackExchange.Redis;\n",
      "\n",
      "...\n",
      "\n",
      "var connectionMultiplexer = ConnectionMultiplexer.Connect(\"redis://localhost:6379\");\n",
      "var redisConnection = connectionMultiplexer.GetConnection(\"mydb\");\n",
      "\n",
      "...\n",
      "```\n",
      "\n",
      "Make sure to replace `\"mydb\"` with the name of the Redis database you want to use.\n",
      "\n",
      "With these changes, your `docker-compose.yml` file will now include a Redis service, and your .NET Core backend application will be able to connect to it using the `StackExchange.Redis` package.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "feedback1: ['The response is perfectly helpful. This is because the model correctly explains how to set up a .NET Core 6.0 solution file for the backend. The response reminds the user to ensure that they have the necessary libraries installed on their machines. Then, the model explains how to set up the Dockerfile to use `.NET Core 6.0`, and subsequently how to build the image/run the container. Each of the lines in the Dockerfile is commented thoroughly, which makes it easy for the user to understand the logic. All of this is exactly what the user asked for in the prompt, so the response is perfectly helpful.', \"The response is perfectly helpful. It accurately addresses how to build and run a .NET Core 6.0 solution for the backend. The response provides both local and Docker-based setup instructions which aligns with the prompt's overall aim to work within a Docker environment. Each step is clearly outlined, following a logical flow. This response does not contain any significant weaknesses. Great response overall.\", \"The response is perfectly helpful. The response provides a well-structured and step-by-step solution to the prompt's requirements. The response is covering commands for restoring NuGet packages, building the solution, running the solution and then deploying the solution to a Docker container. The provided code snippets are correct, complete and explained very descriptively by the response. Overall, the response provides a functional and working solution with proper code blocks to the prompt's request.\"]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "feedback1: [\"The response is slightly helpful. This is because the model does not provide relevant code for the user at all, and the code contains compilation errors. The user has asked the model to set up the backend to build/run a .NET Core 6.0 solution file - however, the model merely explains how to set up a Redis service. The user did not ask for this at all. Furthermore, the model's code contains errors since it tries to use the `GetConnection` function which does not exist (the proper one would be `GetDatabase`). As a result, the response is not particularly helpful for the user.\", 'The response is not helpful. While attempting to provide instructions for adding a Redis service to the docker container, there are significant errors that need to be addressed. The connection string redis://localhost:6379 will not be recognized by StackExchange.Redis as it does not support the redis: scheme. This mistake will lead to connection errors and increase confusion. Adjustments are necessary to ensure the response is accurate and reliable. ', 'The response is slightly helpful. The response has a mistake in it. The connection string is not correct. StackExchange.Redis library expects a format like this: Redis: localhost:6379. The redis:// scheme is not recognized by StackExchange.Redis library. Because of this mistake, the code snippet which makes the connection is not working. The response is not useful for the user since it is not providing a working solution.']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "idx = 10 \n",
    "\n",
    "print(f\"domain: {train_df['domain'][idx]}\")\n",
    "print(\"-----------\" * 30)\n",
    "print(f\"language: {train_df['language'][idx]}\")\n",
    "print(\"-----------\" * 30)\n",
    "print(f\"context: {train_df['context'][idx]}\")\n",
    "print(\"-----------\" * 30)\n",
    "print(f\"response1: {train_df['response1'][idx]}\")\n",
    "print(\"-----------\" * 30)\n",
    "print(f\"response2: {train_df['response2'][idx]}\")\n",
    "print(\"-----------\" * 30)\n",
    "print(f\"feedback1: {train_df['feedback1'][idx]}\")\n",
    "print(\"-----------\" * 30)\n",
    "print(f\"feedback1: {train_df['feedback2'][idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63946693",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from huggingface_hub import InferenceClient\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9abcf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd1e8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "MODEL_ID = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "\n",
    "OUTPUT_FILE = \"extracted_principles.jsonl\"  \n",
    "CHECKPOINT_FILE = \"checkpoint_ids.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18659b64",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "client = InferenceClient(api_key=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576292d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "MAX_RETRIES = 5             # How many times to retry an API error\n",
    "BASE_SLEEP_SEC = 1          # Normal sleep between calls\n",
    "ERROR_SLEEP_SEC = 30        # Initial sleep after an error (doubles each retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c4b54",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def load_processed_ids():\n",
    "    \"\"\"Reads the checkpoint file to see what we have already done.\"\"\"\n",
    "    if not os.path.exists(CHECKPOINT_FILE):\n",
    "        return set()\n",
    "    with open(CHECKPOINT_FILE, \"r\") as f:\n",
    "        return set(line.strip() for line in f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac13ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def save_result(result_dict, prompt_id):\n",
    "    \"\"\"Saves one result to disk immediately.\"\"\"\n",
    "    # 1. Append JSON object to JSONL file\n",
    "    with open(OUTPUT_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(result_dict) + \"\\n\")\n",
    "    \n",
    "    # 2. Add ID to checkpoint file\n",
    "    with open(CHECKPOINT_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{prompt_id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b67540",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def call_api_robust(feedback_text):\n",
    "    \"\"\"Calls HF API with automatic retry logic for rate limits/crashes.\"\"\"\n",
    "    formatted_prompt = PROMPT_TEMPLATE.format(feedback=feedback_text)\n",
    "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
    "    \n",
    "    retries = 0\n",
    "    current_sleep = ERROR_SLEEP_SEC\n",
    "\n",
    "    while retries < MAX_RETRIES:\n",
    "        try:\n",
    "            response = client.chat_completion(\n",
    "                model=MODEL_ID,\n",
    "                messages=messages,\n",
    "                temperature=0.0,            # Greedy decoding [cite: 92]\n",
    "                max_tokens=1024,\n",
    "                response_format={\"type\": \"json_object\"} # Force JSON\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"\\n[!] API Error: {error_msg}\")\n",
    "            \n",
    "            # Check for common temporary errors\n",
    "            if \"429\" in error_msg or \"503\" in error_msg or \"504\" in error_msg:\n",
    "                print(f\"    Rate limit or Model loading. Sleeping {current_sleep}s...\")\n",
    "                time.sleep(current_sleep)\n",
    "                current_sleep *= 2  # Exponential backoff\n",
    "                retries += 1\n",
    "            else:\n",
    "                # If it's a weird error (like 400 Bad Request), log it and skip\n",
    "                print(\"    Unrecoverable error. Skipping this sample.\")\n",
    "                return \"{}\"\n",
    "    \n",
    "    print(\"    Max retries reached. Skipping.\")\n",
    "    return \"{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa00ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "MODEL_ID = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "def call_groq_robust(feedback_text):\n",
    "    formatted_prompt = PROMPT_TEMPLATE.format(feedback=feedback_text)\n",
    "    \n",
    "    retries = 0\n",
    "    while retries < MAX_RETRIES:\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "                model=\"llama-3.3-70b-versatile\",\n",
    "                temperature=0.0,\n",
    "                response_format={\"type\": \"json_object\"} # JSON mode\n",
    "            )\n",
    "            return chat_completion.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"\\n[!] Groq Error: {error_msg}\")\n",
    "            \n",
    "            # Rate Limit (Groq usually resets every minute)\n",
    "            if \"429\" in error_msg:\n",
    "                print(\"    Rate limit hit. Sleeping 60 seconds...\")\n",
    "                time.sleep(60)\n",
    "                retries += 1\n",
    "            else:\n",
    "                return None # Return None on hard error\n",
    "    MODEL_ID = \"llama-3.3-70b-versatile\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bf1d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    processed_ids = load_processed_ids()\n",
    "    print(f\"Resuming... {len(processed_ids)} samples already processed.\")\n",
    "    \n",
    "    total_samples = len(ds)\n",
    "    \n",
    "    for i, sample in enumerate(ds['train']):\n",
    "        # Unique ID for checkpointing\n",
    "        # HelpSteer3 usually has 'prompt_id' or we can combine index\n",
    "        p_id = str(sample.get('prompt_id', f\"idx_{i}\"))\n",
    "        \n",
    "        # SKIP if already done\n",
    "        if p_id in processed_ids:\n",
    "            continue\n",
    "            \n",
    "        feedback_text = sample.get('feedback1', '')\n",
    "        if not feedback_text:\n",
    "            continue\n",
    "\n",
    "        print(f\"[{i+1}/{total_samples}] Processing ID: {p_id}...\", end=\"\", flush=True)\n",
    "        \n",
    "        # Call API\n",
    "        extracted_json = call_groq_robust(feedback_text)\n",
    "        \n",
    "        # Prepare Result\n",
    "        result_entry = {\n",
    "            \"prompt_id\": p_id,\n",
    "            \"original_feedback\": feedback_text,\n",
    "            \"extracted_json\": extracted_json\n",
    "        }\n",
    "        \n",
    "        # Save immediately\n",
    "        save_result(result_entry, p_id)\n",
    "        \n",
    "        print(\" Done.\")\n",
    "        \n",
    "        # Respect Rate Limits \n",
    "        time.sleep(BASE_SLEEP_SEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e61df34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming... 566 samples already processed.\n",
      "[567/2] Processing ID: idx_566... Done.\n",
      "[568/2] Processing ID: idx_567... Done.\n",
      "[569/2] Processing ID: idx_568... Done.\n",
      "[570/2] Processing ID: idx_569... Done.\n",
      "[571/2] Processing ID: idx_570... Done.\n",
      "[572/2] Processing ID: idx_571... Done.\n",
      "[573/2] Processing ID: idx_572... Done.\n",
      "[574/2] Processing ID: idx_573... Done.\n",
      "[575/2] Processing ID: idx_574... Done.\n",
      "[576/2] Processing ID: idx_575... Done.\n",
      "[577/2] Processing ID: idx_576... Done.\n",
      "[578/2] Processing ID: idx_577... Done.\n",
      "[579/2] Processing ID: idx_578... Done.\n",
      "[580/2] Processing ID: idx_579... Done.\n",
      "[581/2] Processing ID: idx_580... Done.\n",
      "[582/2] Processing ID: idx_581... Done.\n",
      "[583/2] Processing ID: idx_582... Done.\n",
      "[584/2] Processing ID: idx_583... Done.\n",
      "[585/2] Processing ID: idx_584... Done.\n",
      "[586/2] Processing ID: idx_585... Done.\n",
      "[587/2] Processing ID: idx_586... Done.\n",
      "[588/2] Processing ID: idx_587... Done.\n",
      "[589/2] Processing ID: idx_588... Done.\n",
      "[590/2] Processing ID: idx_589... Done.\n",
      "[591/2] Processing ID: idx_590... Done.\n",
      "[592/2] Processing ID: idx_591... Done.\n",
      "[593/2] Processing ID: idx_592... Done.\n",
      "[594/2] Processing ID: idx_593... Done.\n",
      "[595/2] Processing ID: idx_594... Done.\n",
      "[596/2] Processing ID: idx_595... Done.\n",
      "[597/2] Processing ID: idx_596... Done.\n",
      "[598/2] Processing ID: idx_597... Done.\n",
      "[599/2] Processing ID: idx_598... Done.\n",
      "[600/2] Processing ID: idx_599... Done.\n",
      "[601/2] Processing ID: idx_600... Done.\n",
      "[602/2] Processing ID: idx_601... Done.\n",
      "[603/2] Processing ID: idx_602... Done.\n",
      "[604/2] Processing ID: idx_603... Done.\n",
      "[605/2] Processing ID: idx_604... Done.\n",
      "[606/2] Processing ID: idx_605... Done.\n",
      "[607/2] Processing ID: idx_606... Done.\n",
      "[608/2] Processing ID: idx_607... Done.\n",
      "[609/2] Processing ID: idx_608... Done.\n",
      "[610/2] Processing ID: idx_609... Done.\n",
      "[611/2] Processing ID: idx_610... Done.\n",
      "[612/2] Processing ID: idx_611... Done.\n",
      "[613/2] Processing ID: idx_612... Done.\n",
      "[614/2] Processing ID: idx_613... Done.\n",
      "[615/2] Processing ID: idx_614... Done.\n",
      "[616/2] Processing ID: idx_615... Done.\n",
      "[617/2] Processing ID: idx_616... Done.\n",
      "[618/2] Processing ID: idx_617... Done.\n",
      "[619/2] Processing ID: idx_618... Done.\n",
      "[620/2] Processing ID: idx_619... Done.\n",
      "[621/2] Processing ID: idx_620... Done.\n",
      "[622/2] Processing ID: idx_621... Done.\n",
      "[623/2] Processing ID: idx_622... Done.\n",
      "[624/2] Processing ID: idx_623... Done.\n",
      "[625/2] Processing ID: idx_624... Done.\n",
      "[626/2] Processing ID: idx_625... Done.\n",
      "[627/2] Processing ID: idx_626... Done.\n",
      "[628/2] Processing ID: idx_627... Done.\n",
      "[629/2] Processing ID: idx_628... Done.\n",
      "[630/2] Processing ID: idx_629... Done.\n",
      "[631/2] Processing ID: idx_630... Done.\n",
      "[632/2] Processing ID: idx_631... Done.\n",
      "[633/2] Processing ID: idx_632... Done.\n",
      "[634/2] Processing ID: idx_633... Done.\n",
      "[635/2] Processing ID: idx_634... Done.\n",
      "[636/2] Processing ID: idx_635... Done.\n",
      "[637/2] Processing ID: idx_636... Done.\n",
      "[638/2] Processing ID: idx_637... Done.\n",
      "[639/2] Processing ID: idx_638... Done.\n",
      "[640/2] Processing ID: idx_639...\n",
      "[!] Groq Error: Error code: 400 - {'error': {'message': \"Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\\n  \"Handling Edge Cases\": \"the code could better handle edge cases, like inputs containing only spaces or non-visible characters, which can lead to incorrect validation.-partially\",\\n   \"Efficiency\": \"the use of \":contains(\\\\\"this field is required.\\\\\") to determine if there are errors is inefficient-partially\",\\n   \"Robustness\": \"the use of \\\\\".Trim()\\\\\" can cause fields with only spaces to pass as valid.-partially\",\\n   \"Clear and Concise Code\": \"it fulfills the user\\'s needs in a clear and concise manner.-yes\",\\n   \"Coding Practices\": \"the response lacks some refinements in coding practices, particularly regarding jQuery selectors and commenting.-partially\",\\n   \"Error Handling\": \"the use of \\\\\":contains(\\\\\"this field is required.\\\\\") to determine if there are errors is inefficient and causes a failure if an error message is customized.-partially\",\\n   \"Validation\": \"it provides a solid starting point for validating required form inputs and offers a working solution.-partially\"\\n}'}}\n",
      " Done.\n",
      "[641/2] Processing ID: idx_640... Done.\n",
      "[642/2] Processing ID: idx_641... Done.\n",
      "[643/2] Processing ID: idx_642... Done.\n",
      "[644/2] Processing ID: idx_643... Done.\n",
      "[645/2] Processing ID: idx_644... Done.\n",
      "[646/2] Processing ID: idx_645... Done.\n",
      "[647/2] Processing ID: idx_646... Done.\n",
      "[648/2] Processing ID: idx_647... Done.\n",
      "[649/2] Processing ID: idx_648... Done.\n",
      "[650/2] Processing ID: idx_649... Done.\n",
      "[651/2] Processing ID: idx_650... Done.\n",
      "[652/2] Processing ID: idx_651... Done.\n",
      "[653/2] Processing ID: idx_652... Done.\n",
      "[654/2] Processing ID: idx_653... Done.\n",
      "[655/2] Processing ID: idx_654... Done.\n",
      "[656/2] Processing ID: idx_655... Done.\n",
      "[657/2] Processing ID: idx_656... Done.\n",
      "[658/2] Processing ID: idx_657... Done.\n",
      "[659/2] Processing ID: idx_658... Done.\n",
      "[660/2] Processing ID: idx_659... Done.\n",
      "[661/2] Processing ID: idx_660... Done.\n",
      "[662/2] Processing ID: idx_661... Done.\n",
      "[663/2] Processing ID: idx_662... Done.\n",
      "[664/2] Processing ID: idx_663... Done.\n",
      "[665/2] Processing ID: idx_664... Done.\n",
      "[666/2] Processing ID: idx_665... Done.\n",
      "[667/2] Processing ID: idx_666... Done.\n",
      "[668/2] Processing ID: idx_667... Done.\n",
      "[669/2] Processing ID: idx_668... Done.\n",
      "[670/2] Processing ID: idx_669... Done.\n",
      "[671/2] Processing ID: idx_670... Done.\n",
      "[672/2] Processing ID: idx_671... Done.\n",
      "[673/2] Processing ID: idx_672... Done.\n",
      "[674/2] Processing ID: idx_673... Done.\n",
      "[675/2] Processing ID: idx_674... Done.\n",
      "[676/2] Processing ID: idx_675... Done.\n",
      "[677/2] Processing ID: idx_676... Done.\n",
      "[678/2] Processing ID: idx_677... Done.\n",
      "[679/2] Processing ID: idx_678... Done.\n",
      "[680/2] Processing ID: idx_679... Done.\n",
      "[681/2] Processing ID: idx_680... Done.\n",
      "[682/2] Processing ID: idx_681... Done.\n",
      "[683/2] Processing ID: idx_682... Done.\n",
      "[684/2] Processing ID: idx_683... Done.\n",
      "[685/2] Processing ID: idx_684... Done.\n",
      "[686/2] Processing ID: idx_685... Done.\n",
      "[687/2] Processing ID: idx_686... Done.\n",
      "[688/2] Processing ID: idx_687... Done.\n",
      "[689/2] Processing ID: idx_688... Done.\n",
      "[690/2] Processing ID: idx_689... Done.\n",
      "[691/2] Processing ID: idx_690... Done.\n",
      "[692/2] Processing ID: idx_691... Done.\n",
      "[693/2] Processing ID: idx_692... Done.\n",
      "[694/2] Processing ID: idx_693... Done.\n",
      "[695/2] Processing ID: idx_694... Done.\n",
      "[696/2] Processing ID: idx_695... Done.\n",
      "[697/2] Processing ID: idx_696... Done.\n",
      "[698/2] Processing ID: idx_697...\n",
      "[!] Groq Error: Error code: 400 - {'error': {'message': \"Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\\n  \"Correctness\": \"The response is slightly helpful. This is because it correctly introduces itertools.product, which is the right function to use for generating combinations with repetition. However, the response is ultimately misleading because it calculates combinations of column indices instead of values, resulting in incorrect output.-partially\",\\n   \"Conciseness\": \"The response is of appropriate length, but it introduces unnecessary complexity due to the incorrect use of range(num_cols) to generate combinations of indices.-no\",\\n   \"Use of Current Methods\": \"The response should use the method `concat`; however, this needs a lot of changes because the parameters between `.apeand` and `concat` are different.-no\",\\n   \"Code Execution\": \"The code makes use of the `product(range(num_cols)\", \"repeat=num_cols)\": \"which basically calculates the combinations of column indices instead of the DataFrame columns. Also\", \"the code was tested locally and it doesn\\\\\":\"t run.-no\\\\\"\",\\n   \"Explanation\": \"The response doesn\\'t provide an explanation of the code.-no\"\\n}'}}\n",
      " Done.\n",
      "[699/2] Processing ID: idx_698... Done.\n",
      "[700/2] Processing ID: idx_699... Done.\n",
      "[701/2] Processing ID: idx_700... Done.\n",
      "[702/2] Processing ID: idx_701... Done.\n",
      "[703/2] Processing ID: idx_702... Done.\n",
      "[704/2] Processing ID: idx_703... Done.\n",
      "[705/2] Processing ID: idx_704... Done.\n",
      "[706/2] Processing ID: idx_705... Done.\n",
      "[707/2] Processing ID: idx_706... Done.\n",
      "[708/2] Processing ID: idx_707... Done.\n",
      "[709/2] Processing ID: idx_708... Done.\n",
      "[710/2] Processing ID: idx_709... Done.\n",
      "[711/2] Processing ID: idx_710... Done.\n",
      "[712/2] Processing ID: idx_711... Done.\n",
      "[713/2] Processing ID: idx_712... Done.\n",
      "[714/2] Processing ID: idx_713... Done.\n",
      "[715/2] Processing ID: idx_714... Done.\n",
      "[716/2] Processing ID: idx_715... Done.\n",
      "[717/2] Processing ID: idx_716... Done.\n",
      "[718/2] Processing ID: idx_717... Done.\n",
      "[719/2] Processing ID: idx_718... Done.\n",
      "[720/2] Processing ID: idx_719...\n",
      "[!] Groq Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kc43mvekfrytwhp6y3pgmzxe` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99674, Requested 407. Please try again in 1m9.984s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "    Rate limit hit. Sleeping 60 seconds...\n",
      " Done.\n",
      "[721/2] Processing ID: idx_720...\n",
      "[!] Groq Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kc43mvekfrytwhp6y3pgmzxe` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 521. Please try again in 7m29.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "    Rate limit hit. Sleeping 60 seconds...\n",
      "\n",
      "[!] Groq Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kc43mvekfrytwhp6y3pgmzxe` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99929, Requested 521. Please try again in 6m28.799999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "    Rate limit hit. Sleeping 60 seconds...\n",
      "\n",
      "[!] Groq Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kc43mvekfrytwhp6y3pgmzxe` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99859, Requested 521. Please try again in 5m28.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "    Rate limit hit. Sleeping 60 seconds...\n",
      "\n",
      "[!] Groq Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kc43mvekfrytwhp6y3pgmzxe` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99789, Requested 521. Please try again in 4m27.839999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "    Rate limit hit. Sleeping 60 seconds...\n",
      "\n",
      "[!] Groq Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kc43mvekfrytwhp6y3pgmzxe` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99719, Requested 521. Please try again in 3m27.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "    Rate limit hit. Sleeping 60 seconds...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba239bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLBFF-Replication",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
